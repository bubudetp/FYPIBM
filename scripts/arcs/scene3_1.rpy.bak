label scene3_1:

    scene bg classroom_day_left with fade
    n "09:00 AM"

    n """
    The air feels heavier than it did last week.

    Not tense. Not loud. Just... expectant.

    Like the room is holding its breath.
    """

    mc_internal """
    Itâ€™s Monday. Again.

    Same seat. Same view.

    But somethingâ€™s wrong.

    I donâ€™t know what.

    Just... wrong.
    """

    scene bg classroom_board_no_desk with dissolve
    # hayashi enters

    "Hayashi" "Today, we build systems that make decisions."

    n "DECISION TREE CLASSIFIERS"

    "Hayashi" "Youâ€™re at a traffic light. Itâ€™s red. You're late. Do you wait, or do you go?"

    mc_internal "Simple choice. But with consequences."

    "Hayashi" """
    Thatâ€™s the idea behind a decision tree.

    Each node asks a question.

    Each answer leads you to a new question.

    Eventually, you arrive at a decision.
    """

    # ðŸ§  Micro-recap
    n "A decision tree breaks problems down into binary choices â€” branching with every condition."

    n """
    Nemra travels to work. She has five features to consider:

    1. Weather  
    2. Time  
    3. Distance  
    4. Traffic  
    5. Public transport reliability
    """

    "Girl A" "Can I just tell Nemra to call in sick?"

    play sound "light_laughter.ogg"
    pause 1.0

    "Hayashi" "She may, but our model cannot."

    "Hayashi" "To build a tree, we ask: Which feature splits the data best? Thatâ€™s where entropy comes in."

    # ðŸ§  Micro-recap
    n "Entropy measures how mixed or uncertain your data is after a split."

    "Hayashi" """
    The more mixed your data after a split â€” the higher the entropy.

    Our goal is to find the feature that produces the lowest entropy â€” the cleanest split.
    """

    "Hayashi" "In Nemraâ€™s case, time of day gave the most consistent decision. Low entropy. High information gain."

    mc_internal """
    The tree learns where to branch.

    Where to split.

    What to discard.

    How many times have I done the same?
    """

    # ðŸŽ® Feature Split Choice
    menu:
        "Youâ€™re training a model to predict if Nemra takes the bus or not.\nWhich feature most likely gives a clean split?"
        
        "Time of day":
            $ correct_choice = True
            mc_internal "Time's reliable. Predictable."
        "Distance to work":
            $ correct_choice = False
            mc_internal "Maybe... but it's not always the deciding factor."
        "Weather":
            $ correct_choice = False
            mc_internal "Too inconsistent. Too noisy."
        "Reliability score of buses":
            $ correct_choice = "bonus"
            mc_internal "Sometimes reliability matters more than distance."

    if correct_choice == "bonus":
        $ reflection_score += 1
    elif correct_choice == True:
        $ reflection_score += 0.5

    # ðŸ§  Reflection Note (soft, post-choice)
    n "The cleaner the split, the more confident the decision. Thatâ€™s how trees grow â€” not just with data, but with certainty."

    # ðŸ•³ First Vanish
    "Boy A" "So what happens if two features give similar splits?"

    "Hayashi" """
    You compare their information gain.

    But if the gain is equal, the model can choose arbitrarily â€” or based on heuristics.
    """

    pause 0.5

    mc_internal "Itâ€™s subtle. Like the projector screen hiccupped."


    n "Hey, whereâ€™sâ€”"

    "Girl C" "Whereâ€™s who?"

    if girl_c_trusts_you:
        "Girl C (frowning, softer this time)"  
        "Waitâ€¦ you mean Boy A?"

        mc_internal "She... she remembers?"

        "Girl C" "I donâ€™t know why I said I didnâ€™t. I saw him yesterday. I know I did."

        $ remembering += 1
        $ rel_girl_c += 1
    else:
        "Girl C" "Whereâ€™s who?"

        mc_internal """
        No one reacts. No one asks.

        Itâ€™s like he was never there.

        But I remember his voice.

        Just now. Asking about feature choice.
        """


    n "Sometimes the model picks. Sometimes it forgets."

    "Hayashi" "Pruning prevents overfitting. We remove unnecessary branches â€” simplify the model."

    "Hayashi" "You want decisions that generalize â€” not memorize. Precision at the cost of usefulness is wasted computation."

    mc_internal """
    But what if the pruning removes too much?

    What if what we cutâ€¦ matters?

    What if that wasnâ€™t noise?
    """

    # ðŸŽ® Reflection Choice â€“ What would you prune?
    menu:
        "If you were pruning your own treeâ€¦"
        "Bad memories.":
            $ reflection_score += 0.5
            mc_internal "Some branches shouldnâ€™t be revisited."
        "Doubt.":
            $ reflection_score += 1
            mc_internal "Overfitting on fear. Thatâ€™s my real loss function."
        "Connections I didnâ€™t trust.":
            $ reflection_score += 1.5
            mc_internal "Sometimes I think I misclassified people too early."

    $ time_display = "09:43 AM"
    call show_time
    
    if rel_girl_c >= 3.0:
        "Girl C (quietly, before leaving the room)"  
        "If the systemâ€™s pruning usâ€¦ then remembering might be rebellion."

        mc_internal "She doesnâ€™t wait for a reply. Just walks out."

        $ glitches += 1

    n "Only I see it. Then... it's gone."

    pause 2.0

    return
