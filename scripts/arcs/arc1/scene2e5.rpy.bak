label scene2e5:

    $ time_display =  "04:35 PM"
    call show_time

    scene bg library_day with fade

    n """
    The libraryâ€™s quieter than usual.

    No Hayashi today. Just a note on the app:
    """

    n """
    â€œProfessor Hayashi is unwell.

    Please review the final sections of Chapter 2 in Library Room 2.

    Next weekâ€™s lesson will be essential.â€
    """

    if remembering >= 2.0:
        mc_internal "Waitâ€¦ wasnâ€™t this supposed to be taught *in class*? Hayashi skipped this once before."
    else:
        mc_internal "Doesnâ€™t feel strangeâ€¦ until I realize I canâ€™t remember the last part of Chapter 2 at all."

    mc_internal """
    Strange, but... not alarming.

    He warned us last time. Something important is coming.
    """

    n """
    A few of us gather â€” not all, but enough to feel like a class.

    Printouts are waiting on the desk. Marked:
    â€œChapter 2 â€“ Sections 6 & 7. Final Concepts.â€
    """

    "Girl B" "Okay, Iâ€™ll start reading. Section sixâ€¦ Backpropagation and Gradient Descent."

    "Girl C" """
    Backpropagation is the process of calculating the error from a neural networkâ€™s outputâ€¦

    and distributing it backward to update the weights.
    """

    "Boy A" "So likeâ€¦ the model makes a mistake, and it uses that mistake to figure out what part of it was responsible."

    "Girl B" "Exactly. The error gets traced through the network â€” each connection, each node, contributes differently."

    mc_internal """
    The deeper the layer, the less direct influence it has.

    But the feedback still flows. Like guilt passed along a chain.
    """

    # ğŸ§  Micro-recap
    n "Backpropagation lets the network *learn from its own failure* â€” assigning responsibility backward through the layers."

    "Girl A" "And gradient descent is how it adjusts those weights, right?"

    "Girl C" "Yep. It uses a partial derivative â€” basically, a small slice of the error â€” to decide how much each weight should change."

    "Girl C" """
    Gradient descent is an optimization algorithm.

    It adjusts the network step by step in the direction that reduces the cost function â€” that is, the error.
    """

    "Girl C (murmuring, almost to herself)"
    "Maybe learning isnâ€™t about truth. Just... trying again. Softer."

    menu:
        "How do you respond?"
        "Itâ€™s painful. But itâ€™s growth.":
            $ rel_girl_c += 1.0
            n "Learning hurts. But the cost means something."
        "Trying over and over doesnâ€™t mean itâ€™s working.":
            $ rel_girl_c -= 1.0
            n "Some loops just trap you."
        "You okay?":
            $ rel_girl_c += 0.5
            n "You sound like you're talking about more than models."


    "Boy B" "So itâ€™s like hiking downhill blindfolded. You feel around for where the ground slopes down, and you step in that direction."

    "Girl A" "Unless you fall in a valley and get stuck there forever."

    play sound "light_laughter.ogg"
    pause 1.0


    mc_internal """
    The bottom of the curve is where the system is â€œbest.â€

    Where its guesses are closest to the truth.

    But it never knows if it reached the bottom.

    It justâ€¦ trusts the slope.
    """

    # ğŸ§  Micro-recap
    n "Gradient descent doesnâ€™t find the perfect answer â€” just *a better one than before*."

    n "Cost = Â½ Î£ (y - Å·)Â²"

    "Girl B" "So this is how the error is measured â€” sum of the differences between expected and predicted values. Squared, so mistakes donâ€™t cancel each other out."

    mc_internal """
    This isnâ€™t just math.

    Itâ€™s philosophy.

    Failure becomes feedback.

    Error becomes direction.
    """
    

    
    call scene2e5_part2
    return


label scene2e5_part2:

    "Girl A" "Ohhh, I love this one. Hereâ€™s the story:"

    """
    A statistician shoots ten arrows at a target.

    Every arrow misses â€” but they average out to hit the bullseye.

    He shrugs and says: â€˜We got it!â€™
    """

    "Boy B" "Thatâ€™s stats. Precision without meaning."

    "Girl C" "And ML is the opposite. It tolerates being a little wrong, if it means being useful."

    "Girl A" """
    Machine learning generalizes.

    It doesnâ€™t care if one prediction is off â€” as long as the overall performance is good.
    """

    # ğŸ§  Micro-recap
    n "Generalization is the goal â€” not perfection on every point, but consistency across patterns."

    # ğŸ® Reflection prompt
    menu:
        "What kind of system are you?"
        
        "I want to hit the target, no matter what.":
            $ reflection_score += 0.5
            mc_internal "Precision matters. I want to get it right."
        "Iâ€™d rather miss a few and still help someone.":
            $ reflection_score += 1.0
            mc_internal "Maybe usefulness matters more than perfection."
        "Iâ€™d like to understand why I keep missing.":
            $ reflection_score += 1.5
            mc_internal "The system can adjust â€” but only if it sees the pattern."

    # sdsd
    call walk_response_event

    scene bg library_sunset with dissolve
    pause 1.0

    n """
    The sun shifts. The laughter fades into quiet page-turning.

    Someone adds â€œChapter 2 â€“ Doneâ€ to the whiteboard.
    """

    mc_internal """
    We learned everything.

    But Iâ€™m still thinking about Hayashi.

    Why skip this part?

    Why make us finish it?
    """

    # âœ¨ Emotional echo: tie reflection to the final line
    mc_internal """
    Maybe he wanted to see if we could learn without him.

    Or maybe he wanted to know which of us would keep adjustingâ€¦ even when the guidance stopped.
    """

    $ time_display = "05:17 PM"
    
    call show_time

    "Girl C" "Whateverâ€™s coming nextâ€¦ He wants us ready."
    
    call trust_event

    return


label walk_response_event:
    python:
        if walk_response == "training" or walk_response == "silent":
        # "Girl C (quietly, later)"
            renpy.say(n, "Thanks for not laughing at me that day. When I said maybe we were just data.")

            renpy.say(mc_internal, "She remembered. Even if the system didnâ€™t.")
            rel_girl_c += 1.0

label trust_event:
    python:
        if rel_girl_c >= 3.0:
            girl_c_trusts_you = True
        else:
            girl_c_trusts_you = False
